{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43c90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4742141c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'doc1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdoc1.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;28;01mas\u001b[39;00m fp1:\n\u001b[0;32m      2\u001b[0m     s1\u001b[38;5;241m=\u001b[39mfp1\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;28;01mas\u001b[39;00m fp2:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'doc1.txt'"
     ]
    }
   ],
   "source": [
    "with open('doc1.txt','r')as fp1:\n",
    "    s1=fp1.read()\n",
    "with open('doc2.txt','r')as fp2:\n",
    "    s2=fp2.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb3c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization.\n",
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "\n",
    "t1=word_tokenize(s1)\n",
    "t2=word_tokenize(s2)\n",
    "print(t1)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop Words Removal.\n",
    "nltk.download('stopwords')\n",
    "def removal(l):\n",
    "    s=stopwords.words('english')\n",
    "    k=[]\n",
    "    for w in l:\n",
    "        if w not in s:\n",
    "            k.append(w)\n",
    "    return k\n",
    "s3=removal(t1)\n",
    "s4=removal(t2)\n",
    "print(s3)\n",
    "print(s4)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def lem(l):\n",
    "    m=[]\n",
    "    for w in l:\n",
    "        m.append(lemmatizer.lemmatize(w))\n",
    "    return m\n",
    "m1=lem(s3)\n",
    "m2=lem(s4)\n",
    "print(m1)\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233704cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS Tagging\n",
    "p1=nltk.pos_tag(m1)\n",
    "p2=nltk.pos_tag(m2)\n",
    "print(p1)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef9762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf\n",
    "def tf(l):\n",
    "    d={}\n",
    "    for i in l:\n",
    "        if i in d:\n",
    "            d[i]+=1\n",
    "        else:\n",
    "            d[i]=1\n",
    "    count=sum(d.values())\n",
    "    for i in d:\n",
    "        d[i]=d[i]/count\n",
    "    return d\n",
    "y1=tf(m1)\n",
    "y2=tf(m2)\n",
    "print(y1)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea22986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idf\n",
    "import math\n",
    "def idf(l):\n",
    "    corpusdict={}\n",
    "    for i in y1:\n",
    "        if i in y2:\n",
    "            corpusdict[i]=2\n",
    "        else:\n",
    "            corpusdict[i]=1\n",
    "    for i in y2:\n",
    "        if i not in y1:\n",
    "            corpusdict[i]=1\n",
    "    idf={}\n",
    "    for i in corpusdict:\n",
    "        idf[i]=math.log(2/corpusdict[i])\n",
    "    return idf\n",
    "i1=idf(m1)\n",
    "i2=idf(m2)\n",
    "print(\"IDF is\",i1)\n",
    "print(\"IDF is\",i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf idf\n",
    "def tfidf(d,idf):\n",
    "    dict={}\n",
    "    for i in d:\n",
    "        dict[i]=d[i]*idf[i]\n",
    "    return dict\n",
    "tfidf1=tfidf(y1,i1)\n",
    "tfidf2=tfidf(y2,i2)\n",
    "print(tfidf1)\n",
    "print(tfidf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f76f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
